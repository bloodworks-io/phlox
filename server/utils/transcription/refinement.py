import json
import logging
import random
import re
from datetime import datetime
from typing import Dict, List, Union

from server.database.config import config_manager
from server.schemas.grammars import (
    NarrativeResponse,
    RefinedResponse,
)
from server.schemas.templates import TemplateField
from server.utils.llm_client.client import get_llm_client

# Set up module-level logger
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)


async def refine_field_content(
    content: Union[str, Dict], field: TemplateField, is_ambient: bool = True
) -> Union[str, Dict]:
    """
    Refine the content of a single field using style examples and format schema.
    Handles special case for thinking models via the client abstraction.
    """

    max_retries = 1

    for attempt in range(max_retries + 1):
        try:
            if isinstance(content, dict):
                return content

            config = config_manager.get_config()
            client = get_llm_client()
            prompts = config_manager.get_prompts_and_options()
            options = prompts["options"]["general"]

            # Determine format details
            format_details = determine_format_details(field, prompts)

            # Build system prompt with style example if available
            system_prompt = build_system_prompt(
                field, format_details, prompts, is_ambient
            )

            base_messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": content},
            ]

            # Generate random seed for diversity in outputs
            random_seed = random.randint(0, 2**32 - 1)

            logger.info(
                f"Refining field {field.field_key} (attempt {attempt + 1}/{max_retries + 1})..."
            )

            # Always use structured output helper; it handles thinking models internally
            response_json = await client.chat_with_structured_output(
                model=config["PRIMARY_MODEL"],
                messages=base_messages,
                schema=format_details["response_format"],
                options={**options, "seed": random_seed},
            )

            # Reuse existing formatter by wrapping the JSON string
            pseudo_response = {"message": {"content": response_json}}
            return format_refined_response(
                pseudo_response, field, format_details
            )

        except Exception as e:
            if attempt < max_retries:
                logger.warning(
                    f"Error refining field {field.field_key} (attempt {attempt + 1}/{max_retries + 1}): {e}. Retrying..."
                )
                continue
            else:
                logger.error(
                    f"Error refining field {field.field_key} after {max_retries + 1} attempts: {e}"
                )
                raise


def determine_format_details(field: TemplateField, prompts: dict) -> dict:
    """Determine response format and format type based on field schema."""

    format_type = None
    if field.format_schema and "type" in field.format_schema:
        format_type = field.format_schema["type"]

        if format_type == "narrative":
            return {
                "format_type": "narrative",
                "response_format": NarrativeResponse.model_json_schema(),
                "base_prompt": "Format the following content as a cohesive narrative paragraph.",
            }

    # Default to RefinedResponse for non-narrative formats
    format_guidance = ""
    if format_type == "numbered":
        format_guidance = (
            "Format the key points as a numbered list (1., 2., etc.)."
        )
    elif format_type == "bullet":
        format_guidance = (
            "Format the key points as a bulleted list (•) prefixes)."
        )

    return {
        "format_type": format_type,
        "response_format": RefinedResponse.model_json_schema(),
        "base_prompt": prompts["prompts"]["refinement"]["system"],
        "format_guidance": format_guidance,
    }


def build_system_prompt(
    field: TemplateField,
    format_details: dict,
    prompts: dict,
    is_ambient: bool = True,
) -> str:
    """Build the system prompt using format guidance and style examples."""
    logger.info(f"Building system prompt for field: {field.field_name}")

    schema_str = json.dumps(format_details["response_format"], indent=2)

    if is_ambient:
        context_description = "The medical information is a summary of a patient transcript. The summary was generated by an automated system therefore it may contain irrelevant information."
        content_constraint = "Preserve ALL important clinical details from the original text; information which is irrelevant to the clinical encounter should be removed."
    else:
        context_description = "The medical information consists of direct clinician dictation. It may contain verbal disfluencies, self-corrections, or stream-of-consciousness phrasing."
        content_constraint = "Preserve clinical intent but intelligently resolve verbal self-corrections (e.g., '...actually, wait, it was tender'). If the clinician contradicts themselves, prioritize the most recent statement. Remove non-medical conversational filler."

    # Check if field has style_example and prioritize it
    if hasattr(field, "style_example") and field.style_example:
        system_prompt = f"""
        You are an expert medical scribe. Your task is to reformat medical information to precisely match the style example provided, while maintaining clinical accuracy. {context_description}

        STYLE EXAMPLE:
            {field.style_example}

        FORMATTING INSTRUCTIONS:
        1. Analyze the STYLE EXAMPLE and match it EXACTLY, including:
        - Format elements (bullet style, indentation, paragraph structure)
        - Sentence structure (fragments vs. complete sentences)
        - Capitalization and punctuation patterns
        - Abbreviation conventions and medical terminology style
        - Tense (past/present) and perspective (first/third person)

        2. IMPORTANT CONSTRAINTS:
        - {content_constraint}
        - Do not add information not present in the input
        - If the style example uses abbreviations like "SNT" or "HSM", use similar appropriate medical abbreviations
        - Return JSON

        FORMAT THE FOLLOWING MEDICAL INFORMATION:"""
    else:
        # If no style example, start with base prompt
        system_prompt = format_details["base_prompt"]

        # Add format guidance if available
        if (
            "format_guidance" in format_details
            and format_details["format_guidance"]
        ):
            system_prompt += "\n" + format_details["format_guidance"]

        # Apply custom refinement rules if specified and no style example exists
        if field.refinement_rules:
            for rule in field.refinement_rules:
                if rule in prompts["prompts"]["refinement"]:
                    system_prompt = prompts["prompts"]["refinement"][rule]
                    break

    # Add adaptive_refinement_instructions if they exist
    # This should be appended regardless of whether a style_example or refinement_rule was applied,
    # as they are supplementary.
    if (
        hasattr(field, "adaptive_refinement_instructions")
        and field.adaptive_refinement_instructions
    ):
        instructions_string = "\n\nAdditionally, consider these user-derived preferences to improve the output further:"
        for i, instruction in enumerate(field.adaptive_refinement_instructions):
            instructions_string += f"\n- {instruction}"
        system_prompt += instructions_string

    return system_prompt


def format_refined_response(
    response: dict, field: TemplateField, format_details: dict
) -> str:
    """Format the model response according to field requirements."""
    format_type = format_details["format_type"]

    if format_type == "narrative":
        narrative_response = NarrativeResponse.model_validate_json(
            response["message"]["content"]
        )
        return narrative_response.narrative

    # Handle non-narrative formats
    refined_response = RefinedResponse.model_validate_json(
        response["message"]["content"]
    )

    if format_type == "numbered":
        return _format_numbered_list(refined_response.key_points)
    elif format_type == "bullet":
        return _format_bulleted_list(refined_response.key_points, field)
    else:
        # No specific formatting required
        return "\n".join(refined_response.key_points)


def _format_numbered_list(key_points: List[str]) -> str:
    """Format key points as a numbered list."""
    formatted_key_points = []
    for i, point in enumerate(key_points):
        # Strip any existing numbering
        cleaned_point = re.sub(r"^\d+\.\s*", "", point.strip())
        formatted_key_points.append(f"{i+1}. {cleaned_point}")
    return "\n".join(formatted_key_points)


def _format_bulleted_list(key_points: List[str], field: TemplateField) -> str:
    """Format key points as a bulleted list."""
    bullet_char = "•"  # Default bullet character
    if field.format_schema and "bullet_char" in field.format_schema:
        bullet_char = field.format_schema["bullet_char"]

    formatted_key_points = []
    for point in key_points:
        # Strip any existing bullets
        cleaned_point = re.sub(r"^[•\-\*]\s*", "", point.strip())
        formatted_key_points.append(f"{bullet_char} {cleaned_point}")
    return "\n".join(formatted_key_points)
